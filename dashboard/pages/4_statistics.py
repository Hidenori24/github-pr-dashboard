# pages/4_statistics.py - çµ±è¨ˆæƒ…å ±ã¨é€±é–“ãƒ¬ãƒãƒ¼ãƒˆ
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta, timezone
from zoneinfo import ZoneInfo
import json

import config
import db_cache

st.set_page_config(page_title="çµ±è¨ˆæƒ…å ±ãƒ»é€±é–“ãƒ¬ãƒãƒ¼ãƒˆ", layout="wide", page_icon="ğŸ“Š")

# Initialize dark mode state if not exists
if 'dark_mode' not in st.session_state:
    st.session_state.dark_mode = False

# Apply custom CSS based on theme
if st.session_state.dark_mode:
    st.markdown(
        """
        <style>
        .stApp { background-color: #1a1a1a; color: #e4e4e7; }
        h1, h2, h3 { color: #e4e4e7; font-weight: 700; }
        section[data-testid="stSidebar"] { background-color: #262626; }
        div[data-testid="stMetric"] { 
            background: linear-gradient(135deg, #2a2a2a 0%, #333333 100%);
            border: 1px solid #3f3f46;
            border-radius: 12px;
            padding: 16px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
        }
        .insight-card {
            background: linear-gradient(135deg, #2a2a2a 0%, #333333 100%);
            border-left: 4px solid #3b82f6;
            padding: 1rem;
            border-radius: 0.5rem;
            margin: 1rem 0;
            border: 1px solid #3f3f46;
        }
        .recommendation {
            background: #1e3a8a22;
            border-left: 4px solid #3b82f6;
            padding: 1rem;
            border-radius: 0.5rem;
            margin: 0.5rem 0;
        }
        .warning-insight {
            background: #7c2d1222;
            border-left: 4px solid #ef4444;
            padding: 1rem;
            border-radius: 0.5rem;
            margin: 0.5rem 0;
        }
        .success-insight {
            background: #14532d22;
            border-left: 4px solid #10b981;
            padding: 1rem;
            border-radius: 0.5rem;
            margin: 0.5rem 0;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )
else:
    st.markdown(
        """
        <style>
        h1, h2, h3 { font-weight: 700; }
        div[data-testid="stMetric"] { 
            background: linear-gradient(135deg, #ffffff 0%, #f5f7fa 100%);
            border: 1px solid #e5e7eb;
            border-radius: 12px;
            padding: 16px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.08);
        }
        .insight-card {
            background: linear-gradient(135deg, #ffffff 0%, #f5f7fa 100%);
            border-left: 4px solid #3b82f6;
            padding: 1rem;
            border-radius: 0.5rem;
            margin: 1rem 0;
            border: 1px solid #e5e7eb;
        }
        .recommendation {
            background: #eff6ff;
            border-left: 4px solid #3b82f6;
            padding: 1rem;
            border-radius: 0.5rem;
            margin: 0.5rem 0;
        }
        .warning-insight {
            background: #fef2f2;
            border-left: 4px solid #ef4444;
            padding: 1rem;
            border-radius: 0.5rem;
            margin: 0.5rem 0;
        }
        .success-insight {
            background: #f0fdf4;
            border-left: 4px solid #10b981;
            padding: 1rem;
            border-radius: 0.5rem;
            margin: 0.5rem 0;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

JST = ZoneInfo("Asia/Tokyo")


# NOTE: This function is defined for potential future use and may also be imported by other modules.
def calculate_business_hours(start_dt: datetime, end_dt: datetime) -> float:
    """å–¶æ¥­æ—¥ï¼ˆå¹³æ—¥ã®ã¿ï¼‰ã§çµŒéæ™‚é–“ã‚’è¨ˆç®—ï¼ˆæ™‚é–“å˜ä½ï¼‰"""
    if pd.isna(start_dt) or pd.isna(end_dt):
        return 0.0
    
    if isinstance(start_dt, str):
        start_dt = pd.to_datetime(start_dt, format="ISO8601", utc=True)
    if isinstance(end_dt, str):
        end_dt = pd.to_datetime(end_dt, format="ISO8601", utc=True)
    
    if start_dt.date() == end_dt.date():
        if start_dt.weekday() >= 5:
            return 0.0
        return (end_dt - start_dt).total_seconds() / 3600
    
    current = start_dt
    total_hours = 0.0
    
    while current.date() < end_dt.date():
        if current.weekday() < 5:
            next_day = datetime.combine(current.date() + timedelta(days=1), datetime.min.time(), tzinfo=current.tzinfo)
            total_hours += (next_day - current).total_seconds() / 3600
        current = datetime.combine(current.date() + timedelta(days=1), datetime.min.time(), tzinfo=current.tzinfo)
    
    if end_dt.weekday() < 5:
        day_start = datetime.combine(end_dt.date(), datetime.min.time(), tzinfo=end_dt.tzinfo)
        total_hours += (end_dt - day_start).total_seconds() / 3600
    
    return total_hours


def generate_weekly_statistics(df: pd.DataFrame, current_week_df: pd.DataFrame, previous_week_df: pd.DataFrame) -> dict:
    """é€±é–“çµ±è¨ˆã‚’ç”Ÿæˆ"""
    stats = {}
    
    # åŸºæœ¬çµ±è¨ˆ
    stats['total_prs'] = len(current_week_df)
    stats['open_prs'] = len(current_week_df[current_week_df['state'] == 'OPEN'])
    stats['merged_prs'] = len(current_week_df[current_week_df['state'] == 'MERGED'])
    stats['closed_prs'] = len(current_week_df[current_week_df['state'] == 'CLOSED'])
    
    # å‰é€±æ¯”
    prev_total = len(previous_week_df)
    stats['total_change'] = stats['total_prs'] - prev_total
    stats['total_change_pct'] = (stats['total_change'] / prev_total * 100) if prev_total > 0 else 0
    
    # ãƒ¬ãƒ“ãƒ¥ãƒ¼æ™‚é–“
    merged_current = current_week_df[current_week_df['state'] == 'MERGED']
    if not merged_current.empty:
        merged_current_copy = merged_current.copy()
        merged_current_copy['lead_time'] = (
            pd.to_datetime(merged_current_copy['mergedAt'], format="ISO8601", utc=True) - 
            pd.to_datetime(merged_current_copy['createdAt'], format="ISO8601", utc=True)
        ).dt.total_seconds() / 3600 / 24
        stats['avg_lead_time'] = merged_current_copy['lead_time'].median()
    else:
        stats['avg_lead_time'] = 0
    
    # å‰é€±ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æ™‚é–“
    merged_prev = previous_week_df[previous_week_df['state'] == 'MERGED']
    if not merged_prev.empty:
        merged_prev_copy = merged_prev.copy()
        merged_prev_copy['lead_time'] = (
            pd.to_datetime(merged_prev_copy['mergedAt'], format="ISO8601", utc=True) - 
            pd.to_datetime(merged_prev_copy['createdAt'], format="ISO8601", utc=True)
        ).dt.total_seconds() / 3600 / 24
        prev_lead_time = merged_prev_copy['lead_time'].median()
        stats['lead_time_change'] = stats['avg_lead_time'] - prev_lead_time
    else:
        stats['lead_time_change'] = 0
    
    # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªé–‹ç™ºè€…æ•°
    stats['active_authors'] = current_week_df['author'].nunique()
    
    # ãƒ¬ãƒ“ãƒ¥ãƒ¼çµ±è¨ˆ
    total_reviews = 0
    total_comments = 0
    for _, row in current_week_df.iterrows():
        total_reviews += row.get('reviews_count', 0)
        total_comments += row.get('comments_count', 0)
    
    stats['total_reviews'] = total_reviews
    stats['total_comments'] = total_comments
    stats['avg_reviews_per_pr'] = total_reviews / stats['total_prs'] if stats['total_prs'] > 0 else 0
    stats['avg_comments_per_pr'] = total_comments / stats['total_prs'] if stats['total_prs'] > 0 else 0
    
    return stats


def generate_insights(stats: dict, df_all: pd.DataFrame) -> list:
    """çµ±è¨ˆã‹ã‚‰æ´å¯Ÿã‚’ç”Ÿæˆ"""
    insights = []
    
    # PRä½œæˆæ•°ã®å¤‰åŒ–
    if stats['total_change_pct'] > 20:
        insights.append({
            'type': 'success',
            'title': 'é–‹ç™ºæ´»å‹•ãŒæ´»ç™ºåŒ–',
            'message': f"å…ˆé€±ã¨æ¯”è¼ƒã—ã¦PRä½œæˆæ•°ãŒ{stats['total_change_pct']:.0f}%å¢—åŠ ã—ã¾ã—ãŸã€‚ãƒãƒ¼ãƒ ã®é–‹ç™ºé€Ÿåº¦ãŒå‘ä¸Šã—ã¦ã„ã¾ã™ã€‚"
        })
    elif stats['total_change_pct'] < -20:
        insights.append({
            'type': 'warning',
            'title': 'é–‹ç™ºæ´»å‹•ã®ä½ä¸‹',
            'message': f"å…ˆé€±ã¨æ¯”è¼ƒã—ã¦PRä½œæˆæ•°ãŒ{abs(stats['total_change_pct']):.0f}%æ¸›å°‘ã—ã¾ã—ãŸã€‚åŸå› ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"
        })
    
    # ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã®å¤‰åŒ–
    if stats['lead_time_change'] < -1:
        insights.append({
            'type': 'success',
            'title': 'ãƒ¬ãƒ“ãƒ¥ãƒ¼é€Ÿåº¦ã®æ”¹å–„',
            'message': f"ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†ã¾ã§ã®æ™‚é–“ãŒ{abs(stats['lead_time_change']):.1f}æ—¥çŸ­ç¸®ã•ã‚Œã¾ã—ãŸã€‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ãŒåŠ¹ç‡åŒ–ã—ã¦ã„ã¾ã™ã€‚"
        })
    elif stats['lead_time_change'] > 2:
        insights.append({
            'type': 'warning',
            'title': 'ãƒ¬ãƒ“ãƒ¥ãƒ¼é…å»¶ã®å¢—åŠ ',
            'message': f"ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†ã¾ã§ã®æ™‚é–“ãŒ{stats['lead_time_change']:.1f}æ—¥å¢—åŠ ã—ã¾ã—ãŸã€‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        })
    
    # ãƒãƒ¼ã‚¸ç‡
    merge_rate = (stats['merged_prs'] / stats['total_prs'] * 100) if stats['total_prs'] > 0 else 0
    if merge_rate < 30:
        insights.append({
            'type': 'warning',
            'title': 'ãƒãƒ¼ã‚¸ç‡ãŒä½ã„',
            'message': f"ä»Šé€±ã®ãƒãƒ¼ã‚¸ç‡ã¯{merge_rate:.0f}%ã§ã™ã€‚OPENã¾ãŸã¯CLOSEDã®PRãŒå¤šãæ®‹ã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
        })
    
    # ãƒ¬ãƒ“ãƒ¥ãƒ¼æ´»å‹•
    if stats['avg_reviews_per_pr'] < 1:
        insights.append({
            'type': 'warning',
            'title': 'ãƒ¬ãƒ“ãƒ¥ãƒ¼æ´»å‹•ã®ä¸è¶³',
            'message': f"PRå½“ãŸã‚Šã®å¹³å‡ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ãŒ{stats['avg_reviews_per_pr']:.1f}å›ã§ã™ã€‚ãƒ¬ãƒ“ãƒ¥ãƒ¼æ´»å‹•ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã§å“è³ªå‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚"
        })
    elif stats['avg_reviews_per_pr'] > 3:
        insights.append({
            'type': 'info',
            'title': 'æ´»ç™ºãªãƒ¬ãƒ“ãƒ¥ãƒ¼æ´»å‹•',
            'message': f"PRå½“ãŸã‚Šã®å¹³å‡ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ãŒ{stats['avg_reviews_per_pr']:.1f}å›ã§ã™ã€‚ãƒãƒ¼ãƒ å…¨ä½“ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ç©æ¥µçš„ã«å‚åŠ ã—ã¦ã„ã¾ã™ã€‚"
        })
    
    # æ»ç•™PR
    open_prs = df_all[df_all['state'] == 'OPEN'].copy()
    if not open_prs.empty:
        now = datetime.now(timezone.utc)
        open_prs['age_days'] = (now - pd.to_datetime(open_prs['createdAt'], format="ISO8601", utc=True)).dt.total_seconds() / 86400
        stale_prs = open_prs[open_prs['age_days'] > 7]
        
        if len(stale_prs) > 5:
            insights.append({
                'type': 'warning',
                'title': 'æ»ç•™PRã®å¢—åŠ ',
                'message': f"7æ—¥ä»¥ä¸Šæ»ç•™ã—ã¦ã„ã‚‹OPEN PRãŒ{len(stale_prs)}ä»¶ã‚ã‚Šã¾ã™ã€‚å®šæœŸçš„ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"
            })
    
    return insights


def generate_recommendations(stats: dict, insights: list) -> list:
    """æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ"""
    recommendations = []
    
    # ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ãŒé•·ã„å ´åˆ
    if stats['avg_lead_time'] > 5:
        recommendations.append({
            'title': 'ãƒ¬ãƒ“ãƒ¥ãƒ¼æ™‚é–“ã®çŸ­ç¸®',
            'actions': [
                'PRã®ã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹ï¼ˆ1PR = 1æ©Ÿèƒ½ï¼‰',
                'ãƒ¬ãƒ“ãƒ¥ãƒ¼æ‹…å½“è€…ã‚’æ˜ç¤ºçš„ã«ã‚¢ã‚µã‚¤ãƒ³ã™ã‚‹',
                'ãƒ¬ãƒ“ãƒ¥ãƒ¼æ™‚é–“ã‚’å®šä¾‹åŒ–ã™ã‚‹ï¼ˆä¾‹ï¼šæ¯æ—¥åˆå‰ä¸­ï¼‰',
                'Draft PRã‚’æ´»ç”¨ã—ã¦æ—©æœŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å¾—ã‚‹'
            ]
        })
    
    # ãƒ¬ãƒ“ãƒ¥ãƒ¼æ´»å‹•ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
    if stats['avg_reviews_per_pr'] < 1:
        recommendations.append({
            'title': 'ãƒ¬ãƒ“ãƒ¥ãƒ¼æ–‡åŒ–ã®é†¸æˆ',
            'actions': [
                'ãƒšã‚¢ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°/ãƒ¢ãƒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®å°å…¥',
                'ãƒ¬ãƒ“ãƒ¥ãƒ¼æ‹…å½“ã®ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶åº¦',
                'ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã®æ•´å‚™',
                'ãƒ¬ãƒ“ãƒ¥ãƒ¼æ´»å‹•ã®å¯è¦–åŒ–ã¨è¡¨å½°'
            ]
        })
    
    # ãƒãƒ¼ã‚¸ç‡ãŒä½ã„å ´åˆ
    merge_rate = (stats['merged_prs'] / stats['total_prs'] * 100) if stats['total_prs'] > 0 else 0
    if merge_rate < 40:
        recommendations.append({
            'title': 'PRå®Œäº†ç‡ã®å‘ä¸Š',
            'actions': [
                'OPEN PRã®å®šæœŸçš„ãªæ£šå¸ã—',
                'ä¸è¦ãªPRã®ã‚¯ãƒ­ãƒ¼ã‚º',
                'WIPï¼ˆWork In Progressï¼‰ã®è¦‹ãˆã‚‹åŒ–',
                'PRã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†ãƒ«ãƒ¼ãƒ«ã®è¨­å®š'
            ]
        })
    
    # é–‹ç™ºè€…ãŒå°‘ãªã„å ´åˆ
    if stats['active_authors'] < 3:
        recommendations.append({
            'title': 'ãƒãƒ¼ãƒ ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¿ƒé€²',
            'actions': [
                'ã‚¯ãƒ­ã‚¹ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒŠãƒ«ãªé–‹ç™ºä½“åˆ¶ã®æ§‹ç¯‰',
                'ãƒŠãƒ¬ãƒƒã‚¸ã‚·ã‚§ã‚¢ã®æ©Ÿä¼šã‚’å¢—ã‚„ã™',
                'ã‚³ãƒ¼ãƒ‰ã‚ªãƒ¼ãƒŠãƒ¼ã‚·ãƒƒãƒ—ã®åˆ†æ•£',
                'ã‚ªãƒ³ãƒœãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã®æ”¹å–„'
            ]
        })
    
    return recommendations


st.title("ğŸ“Š çµ±è¨ˆæƒ…å ±ãƒ»é€±é–“ãƒ¬ãƒãƒ¼ãƒˆ")

st.markdown("""
ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹ã®ç¾çŠ¶ã‚’ç†è§£ã—ã€æ”¹å–„ã®æ©Ÿä¼šã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã®åŒ…æ‹¬çš„ãªçµ±è¨ˆæƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚
""")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("ãƒ‡ãƒ¼ã‚¿å–å¾—")
    
    # ãƒªãƒã‚¸ãƒˆãƒªé¸æŠ
    if config.REPOSITORIES:
        default_repo_idx = st.session_state.get('primary_repo_index', 0)
        repo_options = [f"{r['name']} ({r['owner']}/{r['repo']})" for r in config.REPOSITORIES]
        selected_repo_idx = st.selectbox(
            "ãƒªãƒã‚¸ãƒˆãƒªé¸æŠ",
            range(len(config.REPOSITORIES)),
            index=default_repo_idx,
            format_func=lambda i: repo_options[i],
            help="config.pyã§è¨­å®šã—ãŸãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰é¸æŠ"
        )
        selected_repo_config = config.REPOSITORIES[selected_repo_idx]
        owner = selected_repo_config["owner"]
        repo = selected_repo_config["repo"]
        
        if selected_repo_idx == st.session_state.get('primary_repo_index', 0):
            st.caption("â­ ãƒ—ãƒ©ã‚¤ãƒãƒªãƒ¼ãƒªãƒã‚¸ãƒˆãƒª")
    else:
        owner = config.DEFAULT_OWNER
        repo = config.DEFAULT_REPO
    
    st.divider()
    
    st.header("ãƒ¬ãƒãƒ¼ãƒˆæœŸé–“")
    report_period = st.selectbox(
        "æœŸé–“ã‚’é¸æŠ",
        ["ä»Šé€±", "å…ˆé€±", "ä»Šæœˆ", "å…ˆæœˆ", "éå»30æ—¥", "éå»90æ—¥"],
        index=0
    )
    
    st.divider()
    
    # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    st.header("ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›")
    if st.button("ğŸ“„ é€±é–“ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", use_container_width=True):
        st.session_state['generate_report'] = True

# ãƒ‡ãƒ¼ã‚¿å–å¾—
cached_data = db_cache.load_prs(owner, repo)

if not cached_data:
    st.error("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚`python fetch_data.py --all` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# DataFrameã«å¤‰æ›
df_all = pd.DataFrame(cached_data)
df_all["createdAt_dt"] = pd.to_datetime(df_all["createdAt"], format="ISO8601", utc=True)
df_all["closedAt_dt"] = pd.to_datetime(df_all["closedAt"], format="ISO8601", utc=True, errors='coerce')
df_all["mergedAt_dt"] = pd.to_datetime(df_all["mergedAt"], format="ISO8601", utc=True, errors='coerce')

# æœŸé–“è¨­å®š
now = datetime.now(timezone.utc)
if report_period == "ä»Šé€±":
    # ä»Šé€±ã®æœˆæ›œæ—¥ã‹ã‚‰ä»Šæ—¥ã¾ã§
    week_start = now - timedelta(days=now.weekday())
    week_end = now
    prev_week_start = week_start - timedelta(days=7)
    prev_week_end = week_start
    period_days = 7
elif report_period == "å…ˆé€±":
    # å…ˆé€±ã®æœˆæ›œæ—¥ã‹ã‚‰æ—¥æ›œæ—¥ã¾ã§
    week_start = now - timedelta(days=now.weekday() + 7)
    week_end = week_start + timedelta(days=7)
    prev_week_start = week_start - timedelta(days=7)
    prev_week_end = week_start
    period_days = 7
elif report_period == "ä»Šæœˆ":
    # ä»Šæœˆã®1æ—¥ã‹ã‚‰ä»Šæ—¥ã¾ã§
    week_start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
    week_end = now
    # å‰æœˆã®åŒã˜æœŸé–“
    if week_start.month == 1:
        prev_week_start = week_start.replace(year=week_start.year - 1, month=12)
    else:
        prev_week_start = week_start.replace(month=week_start.month - 1)
    prev_week_end = prev_week_start + (week_end - week_start)
    period_days = (week_end - week_start).days
elif report_period == "å…ˆæœˆ":
    # å…ˆæœˆã®1æ—¥ã‹ã‚‰æœ«æ—¥ã¾ã§
    first_day = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
    if first_day.month == 1:
        week_start = first_day.replace(year=first_day.year - 1, month=12)
    else:
        week_start = first_day.replace(month=first_day.month - 1)
    week_end = first_day
    # å‰ã€…æœˆ
    if week_start.month == 1:
        prev_week_start = week_start.replace(year=week_start.year - 1, month=12)
    else:
        prev_week_start = week_start.replace(month=week_start.month - 1)
    prev_week_end = week_start
    period_days = (week_end - week_start).days
elif report_period == "éå»30æ—¥":
    week_start = now - timedelta(days=30)
    week_end = now
    prev_week_start = week_start - timedelta(days=30)
    prev_week_end = week_start
    period_days = 30
else:  # éå»90æ—¥
    week_start = now - timedelta(days=90)
    week_end = now
    prev_week_start = week_start - timedelta(days=90)
    prev_week_end = week_start
    period_days = 90

# æœŸé–“ã§ãƒ•ã‚£ãƒ«ã‚¿
current_week_df = df_all[
    (df_all['createdAt_dt'] >= week_start) & 
    (df_all['createdAt_dt'] < week_end)
].copy()

previous_week_df = df_all[
    (df_all['createdAt_dt'] >= prev_week_start) & 
    (df_all['createdAt_dt'] < prev_week_end)
].copy()

# çµ±è¨ˆç”Ÿæˆ
stats = generate_weekly_statistics(df_all, current_week_df, previous_week_df)
insights = generate_insights(stats, df_all)
recommendations = generate_recommendations(stats, insights)

# ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
st.markdown("---")

# ã‚µãƒãƒªãƒ¼ã‚«ãƒ¼ãƒ‰
st.markdown(f"### ğŸ“… {report_period}ã®ã‚µãƒãƒªãƒ¼")
st.caption(f"{week_start.astimezone(JST).strftime('%Y/%m/%d')} - {week_end.astimezone(JST).strftime('%Y/%m/%d')}")

col1, col2, col3, col4 = st.columns(4)

with col1:
    delta_color = "normal" if stats['total_change'] >= 0 else "inverse"
    st.metric(
        "ç·PRæ•°",
        stats['total_prs'],
        delta=f"{stats['total_change']:+d} ({stats['total_change_pct']:+.0f}%)",
        delta_color=delta_color
    )

with col2:
    st.metric(
        "ãƒãƒ¼ã‚¸æ¸ˆã¿",
        stats['merged_prs'],
        delta=f"{(stats['merged_prs']/stats['total_prs']*100):.0f}%" if stats['total_prs'] > 0 else "0%"
    )

with col3:
    delta_text = f"{stats['lead_time_change']:+.1f}æ—¥" if stats['lead_time_change'] != 0 else None
    delta_color = "inverse" if stats['lead_time_change'] > 0 else "normal"
    st.metric(
        "å¹³å‡ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ",
        f"{stats['avg_lead_time']:.1f}æ—¥",
        delta=delta_text,
        delta_color=delta_color
    )

with col4:
    st.metric(
        "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–é–‹ç™ºè€…",
        stats['active_authors']
    )

st.markdown("---")

# ã‚°ãƒ©ãƒ•è¡¨ç¤º
col_left, col_right = st.columns(2)

with col_left:
    st.markdown("#### PRçŠ¶æ…‹ã®å†…è¨³")
    
    state_data = pd.DataFrame({
        'çŠ¶æ…‹': ['OPEN', 'MERGED', 'CLOSED'],
        'ä»¶æ•°': [stats['open_prs'], stats['merged_prs'], stats['closed_prs']]
    })
    
    fig_state = px.pie(
        state_data,
        values='ä»¶æ•°',
        names='çŠ¶æ…‹',
        color='çŠ¶æ…‹',
        color_discrete_map={'OPEN': '#f59e0b', 'MERGED': '#10b981', 'CLOSED': '#6b7280'},
        height=300
    )
    fig_state.update_traces(
        textposition='inside',
        textinfo='percent+label',
        hovertemplate='<b>%{label}</b><br>%{value}ä»¶ (%{percent})<extra></extra>'
    )
    st.plotly_chart(fig_state, use_container_width=True)

with col_right:
    st.markdown("#### ãƒ¬ãƒ“ãƒ¥ãƒ¼æ´»å‹•")
    
    col_a, col_b = st.columns(2)
    with col_a:
        st.metric("ç·ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", stats['total_reviews'])
        st.metric("PRå½“ãŸã‚Šå¹³å‡", f"{stats['avg_reviews_per_pr']:.1f}å›")
    
    with col_b:
        st.metric("ç·ã‚³ãƒ¡ãƒ³ãƒˆæ•°", stats['total_comments'])
        st.metric("PRå½“ãŸã‚Šå¹³å‡", f"{stats['avg_comments_per_pr']:.1f}ä»¶")

st.markdown("---")

# ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
st.markdown("### ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æï¼ˆéå»8é€±é–“ï¼‰")

# éå»8é€±é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
weeks_data = []
for i in range(8, 0, -1):
    week_s = now - timedelta(days=now.weekday() + 7*i)
    week_e = week_s + timedelta(days=7)
    
    week_df = df_all[
        (df_all['createdAt_dt'] >= week_s) & 
        (df_all['createdAt_dt'] < week_e)
    ].copy()
    
    merged_week = week_df[week_df['state'] == 'MERGED']
    if not merged_week.empty:
        merged_week_copy = merged_week.copy()
        merged_week_copy['lead_time'] = (
            pd.to_datetime(merged_week_copy['mergedAt'], format="ISO8601", utc=True) - 
            pd.to_datetime(merged_week_copy['createdAt'], format="ISO8601", utc=True)
        ).dt.total_seconds() / 3600 / 24
        avg_lead = merged_week_copy['lead_time'].median()
    else:
        avg_lead = 0
    
    weeks_data.append({
        'é€±': week_s.strftime('%m/%d'),
        'PRæ•°': len(week_df),
        'ãƒãƒ¼ã‚¸æ•°': len(week_df[week_df['state'] == 'MERGED']),
        'å¹³å‡ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ': avg_lead
    })

trend_df = pd.DataFrame(weeks_data)

col_left, col_right = st.columns(2)

with col_left:
    st.markdown("#### PRä½œæˆæ•°ã®æ¨ç§»")
    fig_trend_pr = go.Figure()
    fig_trend_pr.add_trace(go.Scatter(
        x=trend_df['é€±'],
        y=trend_df['PRæ•°'],
        mode='lines+markers',
        name='PRæ•°',
        line=dict(color='#3b82f6', width=3),
        marker=dict(size=8),
        hovertemplate='<b>%{x}</b><br>PRæ•°: %{y}ä»¶<extra></extra>'
    ))
    fig_trend_pr.update_layout(
        xaxis_title="é€±",
        yaxis_title="PRæ•°",
        height=300,
        margin=dict(l=0, r=0, t=20, b=0),
        hovermode='x unified'
    )
    st.plotly_chart(fig_trend_pr, use_container_width=True)

with col_right:
    st.markdown("#### å¹³å‡ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã®æ¨ç§»")
    fig_trend_lead = go.Figure()
    fig_trend_lead.add_trace(go.Scatter(
        x=trend_df['é€±'],
        y=trend_df['å¹³å‡ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ '],
        mode='lines+markers',
        name='ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ',
        line=dict(color='#f59e0b', width=3),
        marker=dict(size=8),
        hovertemplate='<b>%{x}</b><br>ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ : %{y:.1f}æ—¥<extra></extra>'
    ))
    fig_trend_lead.update_layout(
        xaxis_title="é€±",
        yaxis_title="ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ  (æ—¥)",
        height=300,
        margin=dict(l=0, r=0, t=20, b=0),
        hovermode='x unified'
    )
    st.plotly_chart(fig_trend_lead, use_container_width=True)

st.markdown("---")

# æ´å¯Ÿ
st.markdown("### ğŸ’¡ æ´å¯Ÿ")

if insights:
    for insight in insights:
        if insight['type'] == 'success':
            st.markdown(f"""
            <div class="success-insight">
                <h4 style="margin-top: 0;">âœ… {insight['title']}</h4>
                <p style="margin-bottom: 0;">{insight['message']}</p>
            </div>
            """, unsafe_allow_html=True)
        elif insight['type'] == 'warning':
            st.markdown(f"""
            <div class="warning-insight">
                <h4 style="margin-top: 0;">âš ï¸ {insight['title']}</h4>
                <p style="margin-bottom: 0;">{insight['message']}</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="insight-card">
                <h4 style="margin-top: 0;">â„¹ï¸ {insight['title']}</h4>
                <p style="margin-bottom: 0;">{insight['message']}</p>
            </div>
            """, unsafe_allow_html=True)
else:
    st.info("ä»ŠæœŸã¯ç‰¹è¨˜ã™ã¹ãå¤‰åŒ–ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

st.markdown("---")

# æ”¹å–„ææ¡ˆ
st.markdown("### ğŸ¯ æ”¹å–„ææ¡ˆ")

if recommendations:
    for rec in recommendations:
        with st.expander(f"ğŸ’¡ {rec['title']}", expanded=False):
            st.markdown("**å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³:**")
            for action in rec['actions']:
                st.markdown(f"- {action}")
else:
    st.success("ç¾çŠ¶ã®ãƒ—ãƒ­ã‚»ã‚¹ã¯è‰¯å¥½ã§ã™ã€‚å¼•ãç¶šãç¶­æŒã—ã¦ãã ã•ã„ã€‚")

st.markdown("---")

# é€±é–“ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
if st.session_state.get('generate_report', False):
    st.markdown("### ğŸ“„ é€±é–“ãƒ¬ãƒãƒ¼ãƒˆ")
    
    report_text = f"""# GitHub PR é€±é–“ãƒ¬ãƒãƒ¼ãƒˆ

**ãƒªãƒã‚¸ãƒˆãƒª**: {owner}/{repo}  
**æœŸé–“**: {week_start.astimezone(JST).strftime('%Y/%m/%d')} - {week_end.astimezone(JST).strftime('%Y/%m/%d')}  
**ä½œæˆæ—¥æ™‚**: {datetime.now(JST).strftime('%Y/%m/%d %H:%M:%S')} JST

---

## ã‚µãƒãƒªãƒ¼

- **ç·PRæ•°**: {stats['total_prs']}ä»¶ ({stats['total_change']:+d}ä»¶, {stats['total_change_pct']:+.0f}%)
- **ãƒãƒ¼ã‚¸æ¸ˆã¿**: {stats['merged_prs']}ä»¶ ({(stats['merged_prs']/stats['total_prs']*100):.0f}%)
- **å¹³å‡ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ **: {stats['avg_lead_time']:.1f}æ—¥ ({stats['lead_time_change']:+.1f}æ—¥)
- **ã‚¢ã‚¯ãƒ†ã‚£ãƒ–é–‹ç™ºè€…**: {stats['active_authors']}å

---

## ä¸»ãªæ´å¯Ÿ

"""
    
    for insight in insights:
        report_text += f"\n### {insight['title']}\n\n{insight['message']}\n"
    
    report_text += "\n---\n\n## æ”¹å–„ææ¡ˆ\n\n"
    
    for rec in recommendations:
        report_text += f"\n### {rec['title']}\n\n"
        for action in rec['actions']:
            report_text += f"- {action}\n"
    
    report_text += "\n---\n\n*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ GitHub PR Dashboard ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚*"
    
    st.download_button(
        label="ğŸ“¥ Markdownã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=report_text,
        file_name=f"weekly_report_{week_start.strftime('%Y%m%d')}.md",
        mime="text/markdown"
    )
    
    st.markdown(report_text)
    
    # ãƒªã‚»ãƒƒãƒˆ
    st.session_state['generate_report'] = False

st.markdown("---")

# è©³ç´°çµ±è¨ˆ
with st.expander("ğŸ“Š è©³ç´°çµ±è¨ˆ", expanded=False):
    st.markdown("#### PRä½œæˆè€…åˆ¥çµ±è¨ˆ")
    
    if not current_week_df.empty:
        author_stats = current_week_df.groupby('author').agg({
            'number': 'count',
            'state': lambda x: (x == 'MERGED').sum()
        }).reset_index()
        author_stats.columns = ['ä½œæˆè€…', 'PRæ•°', 'ãƒãƒ¼ã‚¸æ•°']
        author_stats['ãƒãƒ¼ã‚¸ç‡'] = (author_stats['ãƒãƒ¼ã‚¸æ•°'] / author_stats['PRæ•°'] * 100).round(1)
        author_stats = author_stats.sort_values('PRæ•°', ascending=False)
        
        st.dataframe(
            author_stats,
            use_container_width=True,
            height=300
        )
    else:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    st.markdown("#### ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼åˆ¥çµ±è¨ˆ")
    
    reviewer_activities = []
    for _, row in current_week_df.iterrows():
        review_details = row.get("review_details", [])
        if isinstance(review_details, list):
            for review in review_details:
                reviewer = review.get("author")
                if reviewer:
                    reviewer_activities.append({
                        "ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼": reviewer,
                        "PR#": row["number"],
                        "çŠ¶æ…‹": review.get("state")
                    })
    
    if reviewer_activities:
        reviewer_df = pd.DataFrame(reviewer_activities)
        reviewer_stats = reviewer_df.groupby('ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼').agg({
            'PR#': 'nunique',
            'çŠ¶æ…‹': 'count'
        }).reset_index()
        reviewer_stats.columns = ['ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ãŸPRæ•°', 'ç·ãƒ¬ãƒ“ãƒ¥ãƒ¼å›æ•°']
        reviewer_stats = reviewer_stats.sort_values('ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ãŸPRæ•°', ascending=False)
        
        st.dataframe(
            reviewer_stats,
            use_container_width=True,
            height=300
        )
    else:
        st.info("ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
